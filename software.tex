\chapter{Software for experiment control and analysis}\label{chap:software}

[TODO: better screenshots: example.py? Monkeypatch to hide errors in BLACS?]

\lettrine[lines=3]{S}{oftware underlies a huge part} of physicists' work, whether experimental or theoretical. On the experimental side in our field, increasingly complex and precise experiments in atomic physics require increasingly sophisticated control of the lasers, magnetic coils, frequency synthesisers, cameras, etc that interact with the quantum systems we study. These devices necessitate use of some kind of interface between themselves and the experimentalist, and whilst the interfaces of the past were more likely to be knobs and dials on the front of the device, they are increasingly taking the form of software. Software is needed to convert from a smooth ramp of voltages designed to ramp up a magnetic field slowly into a finite list of voltages and times that a device can output with precise timing to make it happen. Software is needed to transmit this data to the device in question, in the format it requires. Software is required to extract the images and voltage traces from cameras and voltage acquisition devices and store them in computer memory or on disk. And finally software is required to compute meaningful results from this raw data.

A large fraction of my time during my PhD was spent developing, maintaining and improving the laboratory control system software suite that has emerged from our group at Monash---the \emph{labscript suite}. Originally envisioned as a Python~\cite{python_software_foundation_python_2018} library for generating arrays of hardware instructions to be programmed into devices via a LabVIEW~\cite{national_instruments_laboratory_2018} Virtual Instrument (\textsc{VI}) in a manner similar to many existing control systems in our field, the software suite grew to encompass most aspects of day-to-day control and analysis in our labs. At present it comprises about five separate programs/libraries, depending on how one chooses to draw the borders between them, that control every aspect of a cold atom physics experiment from setting parameters to analysing results. An overview of the process is shown in Figure~\ref{fig:labscript_flowchart}.

The types of experiments the labscript suite addresses are `shot-based' experiments---ones in which precise timing is required over hardware some some interval of time while the experiment is performed (a `shot'), after which the hardware is inactive until the next shot. Many repetitions of similar shots are often performed to build up measurement statistics or investigate the response of a system to a change in some parameter. This general method of performing experiments is common to many experiments in cold quantum gases and trapped ions~\cite{robins_atom_2013-1, cronin_optics_2009-1}, quantum computation~\cite{negretti_quantum_2011-1, ladd_quantum_2010-1} and quantum simulation~\cite{bloch_quantum_2012-1, blatt_quantum_2012-1}.

In this chapter, I'll first give a quick overview of each program and what it does. Then I'll outline the design and development approaches we have taken with the labscript suite and comment on the effects these choices have had on the course the project has taken over the last few years. Then I'll summarise recent developments since the publication of our paper on the software; \emph{A scripted control system for autonomous hardware-timed experiments}~\cite{starkey_scripted_2013}, which is reproduced at the end of this chapter, and future developments still planned. Further details on the role of each program in the suite and the design underlying it are available in the paper, and a more detailed presentation of the software, its design principles, comparisons with other laboratory control software, and recent and future developments are available in Philip Starkey's thesis~\cite{starkey_thesis_2018}.

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{figures/software/flow_chart_simple-eps-converted-to.pdf}
\caption{The labscript suite comprises a number of libraries and programs allowing one to perform precisely timed experiments, each run of which we call a `shot', using commodity hardware such as devices from SpinCore, NovaTech, National Instruments and others. Experiment logic is described by the user in the form Python code using the \texttt{labscript} Python module, which produces from the user's code a set of low-level instructions appropriate for being programmed into the hardware. The program \texttt{runmanager} provides a graphical interface for inputting parameters into this experiment logic, and allows this process to be repeated to produce multiple sets of instructions for repeated execution of the experiment with different input parameters. Not shown in this flowchart is \texttt{runviewer}, which is a graphical program displaying plots of the instructions that have been generated by \texttt{labscript}. Once the instructions have been generated, the program \texttt{BLACS} (Better Lab Apparatus Control System) is responsible for communicating with the hardware: programming in the generated instructions, beginning the experiment, and saving any acquired data to file. An auxiliary LabVIEW program called \texttt{BIAS} (\texttt{BEC} Image Acquisition System) is used for communication with cameras in Monash quantum fluids group laboratories, though other groups use a number of alternate programs in its place, including a stripped-down derivative of \texttt{BIAS} called \texttt{unBIASed}, as well as several other Python-based `camera servers'. After \texttt{BLACS} is finished with a shot, the data is passed to \texttt{lyse}, which executes user-written analysis scripts on each shot to analyse the results, and also executes scripts that operate on sets of data over multiple shots, producing interactive plots. In addition to providing a graphical interface for setting parameters, \texttt{runmanager} provides a Python library for producing shots with programatically provided parameters, allowing the flowchart to close into a loop and produce shots based on analysis results. This can be used to optimise experiment outcomes with respect to a give figure of merit. Figure reused with permission from Starkey et al.~\cite{starkey_scripted_2013}, \textcopyright\ American Institute of Physics 2013.}\label{fig:labscript_flowchart}
\end{center}
\end{figure}

The labscript suite has been adopted by world-leading research groups at the National Institute of Standards and Technology, the University of Maryland, National Research Laboratories, US Army Research Laboratory, Stanford University, JILA, the University of Rochester, Dartmouth College, Universit\"at T\"ubingen, Bates College, Universit\"at Basel, and Technische Universit\"at Darmstadt. It continues to grow as a collaborative open source software project benefiting the experimental physics community.


\section{The programs}


\subsection{\texttt{labscript}}

\texttt{labscript} isn't a program but rather a library: that is, it is a set of classes, functions and methods that can be called from user-written code. We call labscript a \emph{compiler}, because what the functions, classes and methods within it do is generate tables of low-level instructions appropriate for programming into devices to execute the experiment described by the user. Thus the user writes a line of code like \hbox{\texttt{MOT\_beams.constant(t=3, 1, 'V')}} and this will add an entry to the table of instructions for whichever Digital-to-Analogue Converter (\textsc{dac}) is controlling the \textsc{mot} beams to go to three volts at $t = 3\unit{s}$ after the beginning of the experiment. This is a simple example, but has advantages over having a human write the table directly.\footnote{Most existing control systems in our field are more-or-less in the form of a large table with each row corresponding to a particular time in the experiment, with the user editing values in the table directly, or typing mathematical expressions in the table describing values as a function of time between one row of the table and the next.} After one has told the \texttt{labscript} compiler with this line that the \textsc{mot} beams should have their control voltage set to three volts, it knows that at all later times the same state should remain, until the user says otherwise. Thus the user doesn't need to also change all future rows of the table: it it enough to declare a change. 

\texttt{labscript} automates much of the tedious, repetitive work that is required in generating those lists of voltages, frequencies, and digital values required to control an experiment. This tedium mostly comes from the fact that devices are sharing timing (see the paper for a description of \emph{pseudoclocking}, the method by which the timing of devices is controlled). When one device changes state, several devices may receive a timing pulse at that time, and so they must have an entry in their corresponding tables in order to output the correct value (possibly the same as the previous value they were outputting) at that time, lest they get too far ahead and output a value that was meant for a later time. \texttt{labscript} takes high level descriptions of what voltages etc.~are required at different times, puts them on a common timing base and generates the correct tables of values. It also collects any other instructions such as camera exposure durations, or the position a translation stage should move to at the start of the experiment even though it is not capable of moving quickly during the experiment. These instructions are processed by labscript and saved to a file in the Hierarchical Data Format, version 5~\cite{the_hdf_group_hierarchical_1997} (\textsc{hdf5}). This format is a convenient, standardised, cross-platform, and self-documenting format with widespread adoption across many disciplines, and compatibility with a wide range of programming and analysis environments, providing a high degree of interoperability between the data files produced by the labscript suite and other software tools. For more information on \texttt{labscript} and the other programs in the labscript suite, see the paper reproduced at the end of this chapter, and Philip Starkey's thesis~\cite{starkey_thesis_2018}.

\subsection{\texttt{runmananger}}

A thirty second or so experiment (a typical duration for a \textsc{bec} experiment, though ion trapping experiments are often much shorter) is not the only timescale on which experimentalists require automation. Commonly, the same brief experiment is repeated over a range of input parameters, with several input parameters varying to span some parameter space. In addition to these varying parameters, there are many parameters involved in an experiment that do not vary often, but nonetheless need to be managed. \texttt{runmananger} is a program providing a graphical user interface (\textsc{gui}) for entering and managing these parameters and describing the parameter spaces over which they should vary. Users can enter simple numbers or expressions (including expressions for non-numerical variables) into the interface, or lists of numbers that can optionally be considered a description of a dimension of a parameter space. These dimensions may be combined in an outer product resulting in a larger space, or equal length dimensions may be looped over in tandem, if the two variables are intended to vary together rather than separately.

The \textsc{gui} of \texttt{runmanager} is shown in~\figref{fig:runmanager}. \texttt{runmanager} produces the initial \textsc{hdf5} files that are passed to the user's `experiment script', i.e.~their Python script describing the experiment logic using the \texttt{labscript} library. The user specifies in \texttt{runmanager}'s interface which Python file contains this experiment script, and when they click the `engage' button, \texttt{runmanager} produces one \textsc{hdf5} file---each containing a set of parameters---for each point in the parameter space described by those parameters currently selected in the runmanager interface. For each \textsc{hdf5} file \texttt{runmanager} initialises the \texttt{labscript} library such that these values become global variables from the perspective of the users experiment script, which then runs. For this reason we call the parameters `globals'. After the user's instructions are processed, the \texttt{labscript} library writes the resulting hardware instructions to that same \textsc{hdf5} file.

We refer to the process of passing the \textsc{hdf5} file to the user's code and running it as `compilation', and the resulting \textsc{hdf5} file containing both globals and hardware instructions a `compiled shot file'. Compilation occurs in a separate process from the \texttt{runmanager} graphical interface, allowing a clean separation between user code and \texttt{runmanager}, so that even the most low-level crashes of the user's code cannot crash \texttt{runmanager} and only require a restart of its subprocess. This type of separation is a repeated theme in the labscript suite and has been invaluable for making robust programs that can continue to operate in the case of inevitable crashes of user code, or of bugs within the labscript suite itself.

\begin{figure}[t]
\begin{center}
\includegraphics[width=\textwidth]{figures/software/new_screenshots/runmanager.png}
\caption{\texttt{runmanager} as of 2018, showing the interface for entering `globals', so called because they appear to the user's code as global variables. Boolean globals can be turned on and off with a checkbox, and expressions resulting in an error are highlighted in red. The `expansion' column is where the user specifies whether a global should be considered a list of values to loop over, re-running the experiment each time, and if so if that loop should be combined with other such globals to loop over the resulting product space (`outer') or whether the globals should be looped over together (`zip'). Zipped globals can be grouped together by typing a name in the expansion column to identify which `zip group' the global belongs to. Globals in the same zip group will loop together, and multiple zip groups will form separate axes of a product space.}\label{fig:runmanager}
\end{center}
\end{figure}

\subsection{\texttt{runviewer}}

\begin{figure}[t]
\begin{center}
\includegraphics[width=\textwidth]{figures/software/new_screenshots/runviewer.png}
\caption{The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog}\label{fig:runviewer}
\end{center}
\end{figure}

\texttt{runviewer} is a program for viewing the results of \texttt{labscript} compilation in the form of graphical plots of the voltages, digital values, frequencies etc that comprise the hardware instructions produced. This is useful for debugging experiment design and timing of instructions, as well as verifying that a newly made \texttt{labscript} device class (the `driver' code for each device that converts \texttt{labscript}'s intermediate description of hardware instructions into the actual format required for a given device) is functioning as intended.

\subsection{\texttt{BLACS}}

\texttt{BLACS} (Better Lab Apparatus Control System) is a graphical program responsible for queueing experiment shots as compiled by \texttt{labscript} in tandem with \texttt{runmanager}, and executing them one after the other on the hardware. As such, \texttt{BLACS} interacts with a number of Python classes that function as \emph{drivers} for each devices, containing code that uses the required software libraries, hardware drivers or communication protocols to communicate with the devices in the manner required by each one individually. \texttt{BLACS} executes the code for communicating with each device in a separate process in order to isolate them from each other, so that communication failures, software bugs or other failures that may occur in the interactions with one device will not stop \texttt{BLACS} from continuing to function in other respects. Errors are presented graphically and each device process may be restarted with the click of a button if something goes wrong, re-initialising communication with the offending device. This is useful for both responding to unexpected failure, as well as for debugging during the development of the driver for a new device (or of new features for an existing device) being integrated with the labscript suite.

Upon receiving an \textsc{hdf5} file from \texttt{runmanager}, \texttt{BLACS} adds it to the queue of shots to be executed on the hardware. It then executes these shots in order, by programming the instructions stored in the \textsc{hdf5} file into each device, and then giving the top-level device the command to begin the experiment. Devices are programmed in parallel in their separate processes, saving time.\footnote{Particularly since many delays in programming the devices are communication delays, during which the process is simply idle.} Once the shot is complete, each device process is given the command to write any data acquired to the \textsc{hdf5} file.

\texttt{BLACS} can also repeat shots, by copying and then `cleaning' an \textsc{hdf5} file after it has already run to produce a new shot file ready to be run on the hardware. It can repeat either all the shots, or just the last one in the queue. This ability to always keep running by repeating the last shot in the queue is crucial for experiments using alkali metal dispensers (`getters') or ultraviolet light-induced atom desorption~\cite{klempt_ultraviolet_2006}, as these processes must run on an approximately fixed duty cycle to maintain the desired atomic vapour pressure, otherwise experiments need to `warm up' after being idle to reach adequate pressure.

\afterpage{
    \newgeometry{left=1in,bottom=1.5in,right=1in,top=1.5in}
    \begin{sidewaysfigure}[th]
    \centerfloat
    \includegraphics[width=\textwidth]{figures/software/new_screenshots/blacs.png}
    \caption{\texttt{BLACS} as of 2018, showing the experiment queue to the left and manual controls of devices within a tabbed interface to the right. When a hardware-timed experiment is not in progress, outputs may be controlled manually using this interface. Presently the \texttt{gui} for four devices can be displayed simultaneously (only one is shown here), though we plan to allow \texttt{BLACS} tabs to occupy their own windows or even reside on different computers to allow a better use of screen space.}
    \label{fig:blacs}
    \end{sidewaysfigure}
    \restoregeometry
}

\subsection{\texttt{lyse}}

Once \texttt{BLACS} has finished with a shot, the shot files are optionally passed on to the analysis program \texttt{lyse}. \texttt{lyse} is essentially a scheduler for user-provided analysis routines. A list of analysis routines (in the form of Python scripts), called \emph{single-shot routines} are executed in order whenever a new shot is received by \texttt{lyse}, with the shot file provided as input to each script. The analysis routines may read raw data from the \textsc{hdf5} file, or read analysis results saved by previously-run analysis routines, and save their own results. Analyis routines may also produce plots using the \texttt{matplotlib} library~\cite{Hunter:2007}---\texttt{lyse} detects these and reuses the same window for subsequent plots so that repeated runs of the analysis routines result in the plot updating in-place, rather than a proliferation of plot windows. Any other plotting library can be used (for example \texttt{pyqtgraph}~\cite{campagnola_pyqtgraph_2016}), though the user needs to write their code for the updating behaviour in this case.

The shot globals and analysis results for all shots received by \texttt{lyse} are maintained in a tabular data structure: a `dataframe' provided by the \texttt{pandas}~\cite{mckinney-proc-scipy-2010} Python package, which is browsable in the \texttt{lyse} interface. This table of data is available to a further list of analysis routines, called \emph{multi-shot routines}. This list of analysis routines is also run in sequence, but only once single-shot analysis has completed on all shots presently loaded into \texttt{lyse}. These routines can be analyses of relations between input parameters and analysis results of the shots, in order to say, measure a trend of the number of atoms in a MOT as the magnetic field gradient was varied. Both single-shot and multi-shot routines can be run from within \texttt{lyse}, or externally by running Python manually. In this latter case, the shot file on which to run single shot analysis can be provided as a command line argument, and the dataframe analysed by multi-shot routines can be obtained from a running instance of \texttt{lyse} over the network. This is no different to what happens when multi-shot routines are run from within \texttt{lyse}: they are simply run by \texttt{lyse} with no input, and are expected to call a function \texttt{lyse.data()} to obtain the dataframe containing multi-shot data. Because of the way this is implemented, one can also open an interactive Python interpreter such as IPython~\cite{perez_ipython:_2007} on any computer on the same network, type \texttt{import lyse; df = lyse.data(hostname)} (where \texttt{hostname} is the hostname of the computer running \texttt{lyse}) and begin interactively exploring the data using the \texttt{pandas} library, one of its great strengths.

\afterpage{
    \newgeometry{left=1in,bottom=1.5in,right=1in,top=1.5in}
    \begin{sidewaysfigure}[th]
    \centerfloat
    \includegraphics[width=\textwidth]{figures/software/new_screenshots/lyse.png}
    \caption{\texttt{lyse} as of 2018. To the top left is the list of single-shot routines, and to the right of it the multi-shot routines presently loaded. The list of shots is below them, showing some of the globals and analysis results of these shots. To the right is the output box where any textual output produced by analysis routines is displayed. Overlaid is a plot produced by a single-shot analysis routine [TODO DO THIS.}
    \label{fig:lyse}
    \end{sidewaysfigure}
    \restoregeometry
}

\section{Design philosophy and advantages of approach}

\subsection{It's code}\label{sec:its_code}
The design of our software brings the process of experimental physics closer to that of software development, making it amenable to many of the tools and processes in use in software development such as version control, bug tracking, and textual diffs highlighting changes between versions of experiments. Both the experiment logic and the analysis routines comprise Python code that can be examined for changes using standard `diff' tools, stored in version control, or forked into multiple versions using distributed version control and merged back together again. This can allow risky changes to experiment logic or analysis code to be explored with the reassurance of being able to roll back to a known working state should the changes not prove fruitful. One exception to this `everything is code' philosophy is the globals themselves, which are stored in non-textual \textsc{hdf5} files, though we do have a tool for `diffing' them too to highlight what has changed between two globals files, or between the current set of values configured in \texttt{runmanager} as compared to a particular shot file, which is crucial in the experiment debugging process (\figref{fig:globals_diff}).

\begin{figure}
\begin{center}
\includegraphics[width=0.5\textwidth]{figures/software/globals_diff.png}
\caption{Helpful advice from a PhD student of the Spinor BEC lab}\label{fig:globals_diff}
\end{center}
\end{figure}

As in software development, experimental physics re-uses the same procedures time and time again, and benefits from a way to manage the complexity of turning large parts of functionality on and off or otherwise conditionally modifying its behaviour. In a traditional atomic physics control system, disabling a part of the experiment logic might involve tedious clicking to remove or disable each instruction involved. In Python, this can be a single \texttt{if} statement wrapping a function call containing all the complexity of the part of the experiment being disabled. The ability of high level programming languages to manage complexity via encapsulation and code re-use with functions, classes and modules carries well over to experimental physics. Using an existing programming language saves us---as the developers of the control system---from having to re-invent (likely badly) the features of a programming language within our control system. For example, the tedious clicking required to `comment out' part of an experiment in the aforementioned hypothetical `traditional' control system could be avoided if the system implemented a feature for this functionality in particular. But then what about \emph{nested} if statements? To support all the use cases that might come up, one would have to essentially invent a programming language within such a control system. Use of an existing complete programming language obviates this need.

The use of an existing programming language only aids the labscript suite in the case of `compile-time' conditionals and other control statements--- that can be evaluated when the hardware instructions are produced by \texttt{labscript}, as opposed to `run-time' when the experiment is run on the hardware (such as conditionally turning a laser on if a photon is detected on a photo-detector). Such run time control statements do require special treatment in \texttt{labscript}, and \texttt{labscript} currently only has one type of functionality like this built-in. This is the ability to pause the experiment until a pulse is produced that resumes the `master' pseudoclock. This allows the common use case of synchronisation with the background $50\unit{Hz}$ magnetic noise from mains electricity by pausing the experiment until a fixed point in the $50\unit{Hz}$ cycle to ensure the magnetic field is close to identical from one shot to the next. It also allows servoing of the \textsc{mot} load, by loading for a variable amount of time based on a threshold fluorescence such that variations in \textsc{mot} loading efficiency from one shot to the next do not result in variations in actual atom numbers.

Further run-time control flow tools such as conditional branches would not be too difficult to incorporate into \texttt{labscript} in the future, but would require hardware capable of holding multiple alternative sets of instructions in memory and able to switch between them on a digital edge or the state of a digital signal on some input. The SpinCore PulseBlaster---the device used by most users of the labscript suite to produce clocking pulses---supports this, but most output devices labs use with the labscript suite do not. Custom field-programmable gate arrays (\textsc{fpga}s) implementing this functionality however for digital or analogue output could be integrated with the labscript suite for this purpose, as they have been for other purposes~\cite{gill_optical_2016}.

\subsection{Modularity and the Unix philosophy}\label{sec:unix_philosophy}

An aspect of the Unix philosophy~\cite{gancarz_unix_1995} is that tools should `do one thing and do it well'. The components of the labscript suite are not as minimal as they could be, but are nonetheless discrete components that encapsulate different concerns and communicate with to each other over network connections.\footnote{This is in violation of another part of the Unix philosophy that says programs should exchange text streams: our programs mostly exchange messages over network sockets, containing filenames pointing to \textsc{hdf5} files on a network drive.} Thus in principle once can remove a component and replace it with another that plays a different role. For example, \texttt{runmanager} has been re-purposed by Philip Starkey~\cite{starkey_thesis_2018} to generate parameter space scans for numerical simulations instead of experiments, by calling code other than \texttt{labscript} code. \texttt{lyse} is in use by Fred Jendrzejewski's group at Universit\"at Heidelberg for on-line analysis of experiment results in the form of \textsc{hdf5} files produced by a different data acquisition system.

The separate programs of the labscript suite are also implemented in many cases as a number of processes exchanging instructions over network sockets, even though the collection of processes semantically comprise a single application. This architecture facilitates a fairly direct extension (currently in development) in which different parts of the same program run of different computers. One can then imagine having \texttt{lyse} analysis routines run on a remote computer (perhaps a server with a powerful \textsc{gpu} or many \textsc{cpu} cores for computationally intensive analyses), or to have devices controlled by \texttt{BLACS} be connected to a different computer than the one running \texttt{BLACS}. This latter configuration can aid in reducing the effect of ground loops due to long cables, or allow the simultaneous use of devices that require different operating systems or other conflicting software or hardware configurations preventing them from being used on the same computer.\footnote{A pertinent example is the bandwidth of a computer's \textsc{usb} bus being the limiting factor in the speed at which one lab can run experiments: using two computers to program two \textsc{usb} devices could halve the programming time between shots}.

\texttt{runmanager} is a graphical program, but also a software library for setting globals and compiling shots by running \texttt{labscript} code, and so is in a sense two separate components. As a result, it is possible to write code that produces shots based on something other than the simple parameter space scans \texttt{runmanager} is capable of producing. In the past, the labscript suite contained a program called \texttt{mise}, used for performing optimisation of the experiment. \texttt{mise} would use the \texttt{runmanager} library (but not the graphical interface) to produce shots based on a genetic algorithm and the results of analysis communicated to it by \texttt{lyse} analysis routines. This type of optimisation was powerful, but has been superseded, and we no longer maintain \texttt{mise}. However a similar workflow is used in the spinor BEC laboratory at Monash to integrate the \textsc{mloop} machine-learning optimisation library~\cite{wigley_fast_2016} with the labscript suite for experiment optimisation.

The separation of components also aids in development of the labscript suite. Programs can be ported to use updated versions of libraries one at a time, and tested separately, enabling a more flexible process of development which has proved invaluable to the open-source development process. 


\subsection{Off-the-shelf hardware}

The labscript suite is the software part of an experiment control system, and does not mandate any particular hardware. Whilst certain hardware drivers are developed and maintained by myself and the other labscript suite developers, if one wants to use different hardware, one can write drivers for it and use it with the labscript suite. This does mean that the software cannot make hard assumptions about the hardware and has to deal with a wider range of possibilities, which is a complicating factor in maintaining the code, but I believe this approach is the better one compared to having a limited range of hardware designed specifically for the labscript suite. It is hard to predict what hardware experimentalists will require for atomic physics experiments, and our efforts are better spent making software than hardware. Labscript suite developers and users have made some hardware of their own as well however, and there exists a low-cost pseudoclock and and a digital out device both based on a sub-\$100 microcontroller board (Called the PineBlaster and BitBlaster respectively). However these have proved difficult to maintain in the face of changing software development kits for the microcontrollers, and I suspect \textsc{fpgas}s implementing similar functionality would be a solution with greater longevity. Rory Speirs~\cite{speirs__2018-1} has developed a low-cost \textsc{fpga}-based pseudoclock (planned to be released as an open source project) that may be an attractive alternative to the Spincore PulseBlaster for use with the labscript suite.

\subsection{Open source, popular programming language and data format}

Using open source technologies in the labscript suite, as well as developing the labscript suite itself as an open source project have benefited the project immensely.

The labscript suite itself being open source allows others to modify it to their needs, expanding the range of experiments that it can be used with. If modifications made are applicable to a wide enough range of users, they can be contributed back to the main project. Not least importantly, bugs in the code that have been worked around or fixed by a single end-user can be contributed back to the main project for the benefit of all. This has led to a steady improvement in the usability and stability of the software as usability issues and bugs have been noticed and fixed by people outside the core development team. Sometimes there is disagreement about what features belong in the labscript suite, or more often, over how they should be implemented. The open-source nature of the project allows end users to continue to use an implementation of functionality that there may not be agreement about including in the main project, either permanently or until another implementation is available. This is much more preferable to simply being at the whim of the core developers as to what features they will or will not implement (whether due to differing opinions or to time constraints).\footnote{Although a commercial model has the potential to to work here too, in which users pay for features to be implemented. There is also the `best of both worlds' approach of bug and feature `bounties', where users add a cash reward for implementing certain features or resolving bugs, adopted by some open source software projects.}

The use of third-party open-source technologies in the labscript suite has also been advantageous, as when the projects we rely on do not fully satisfy our needs, there is often the possibility of modifying them to meet those needs. Furthermore, these modifications, if agreeable to the developers of said libraries, can be included in the `upstream' project to remove the requirement that we maintain the patches ourselves. To this end I have had changes accepted into the \texttt{numpy}~\cite{oliphant_guide_2015}, \texttt{pandas}~\cite{mckinney-proc-scipy-2010}, \texttt{pyzmq}~\cite{brian_e._granger_and_contributors_pyzmq_2018} and \texttt{h5py}~\cite{andrew_collette_and_contributors_h5py_2018} projects which improve their behaviour for the labscript suite's purposes. 

The use of a popular programming language such as Python allows new students writing experiment code using \texttt{labscript} to get up to speed with what is necessary to work in their laboratory. Many students and other physicists are already using Python for data analysis and other tasks, and so knowledge of it is more widespread than other languages, decreasing the barrier to entry for modifying the labscript suite or contributing to its development.

The use of the standardised \textsc{hdf5} format, and of the popular \texttt{zeromq}~\cite{zeromq_guide} messaging protocol for communication between components allows interoperability with a wide range of other programming languages and technologies, such that software written in other programming languages can interact with either running labscript suite programs and read the data files produced by them.


\subsection{Collateral benefits}

Developing and maintaining the labscript suite has involved achieving several intermediate, instrumental goals in order to achieve the ultimate goals of the software. Some of these solutions have been packaged as separate software projects, or are available from within the labscript suite, and may be used for other purposes.

For example, as mentioned, the labscript suite comprises several programs, each of which contains multiple threads and/or processes, communicating with each other by message passing (largely in line with the `actor model' of concurrent programming\footnote{Though we had no formal education in this model before writing code in this style, and I attribute my fondness of the model to the computer game \emph{SpaceChem}~\cite{zachtronics_industries_spacechem_2011}, in which the player constructs chemical `reactors' comprising multiple threads of execution exchanging atoms and molecules.}). As such the code contains reusable pieces for launching processes and initiating message passing with them, of redirecting output of subprocesses to some visible location rather than a terminal, or of starting and stopping `servers' and creating `clients' to either pipe data to them continuously or to make discrete requests that necessitate a response. Furthermore, these multiple threads and processes often require access to the same files (the \textsc{hdf5} files containing the data for each experiment run), and access to these files needs to be serialised to prevent data corruption. The solutions to these problems that we have arrived at have been encapsulated into the \texttt{zprocess} project~\cite{christopher_j._billington_zprocess_2018}, an open source software project officially separate from the labscript suite but very much developed to meet its needs for multiprocessing. This project is used not just for the labscript suite, but for other laboratory automation tasks. It is also used in the software implementation of an undergraduate experiment in the School of Physics and Astronomy at Monash University to allow students to remotely control the experiment and collect data over the internet~\cite{monash_university_school_of_physics_and_astronomy_measurement_2016}.

Multi-threaded graphical programs can present development problems as the software library for the graphical interface generally must be accessed only from the one thread. This is generally the case for the Qt toolkit~\cite{the_qt_company_qt_2018} as used in the labscript suite, and so interacting with the graphical interface from multiple threads generally involves message passing to request that an operation be performed in the `main' thread. We have similarly encapsulated our solutions to this---as well as several other problems repeatedly encountered in using the Qt toolkit, such as an icon set, automatic loading of graphical layouts from external files, and others---into the \texttt{qtutils} project~\cite{starkey_qtutils_2018}, which is used for other small graphical utilities in our group, separately from the labscript suite. This library has also been used in an undergraduate teaching context in the School of Physics and Astronomy at Monash University to improve IT infrastructure for digital logbooks used by undergraduate students.

We also have a number of debugging/profiling tools that I often find myself reaching for to debug numerical simulations, or other code unrelated to the labscript suite.


\section{Recent and future developments}

Since the publication of our paper in 2013~\cite{starkey_scripted_2013}, the number of groups using our software has increased considerably, from being limited to just the two groups at Monash, to a modest number of groups around the world.

In 2014 during my PhD I was invited to visit the Joint Quantum Institute in the group of Ian Spielman, with the aim of improving the labscript suite to make it more generally usable and easier for others to install. The primary goal was to port the graphical programs from the \textsc{gtk} toolkit~\cite{the_gnome_project_gtk+_2018} to the Qt toolkit~\cite{the_qt_company_qt_2018}, and to write an installation program that would automate the previously somewhat tedious installation process. These goals were achieved, and the installation process for the labscript suite is now a matter of installing an appropriate Python environment, and then downloading and running our installation script.

The following subsections detail this and a number of other developments since the publication of our paper, as well as planned and in-progress improvements to the labscript suite.

\subsection{Port to Qt}

The port to Qt was a crucial development. As discussed in the publication reproduced at the end of this chapter, we initially chose the \textsc{gtk} toolkit for its cross-platform compatibility and good Python bindings~\cite{riverbank_computing_pyqt_2018}. This has proved to be the wrong decision, as the \textsc{gtk} project has rapidly developed and dropped support for older versions, making them difficult to install on operating systems other than Linux. Although slated as a cross-platform toolkit, the \textsc{gtk} project is developed by and primarily serves the needs of the \textsc{gnome} project~\cite{the_gnome_project_gnome_2018}, and thus its development is driven by those needs. There is little incentive for Windows- or Mac-specific bugs to be fixed, or for the installation process to be improved. Although it's an open source project such that people other than the core developers could contribute fixes to these issues, the Linux-centric nature of the project impedes these fixes from being accepted for inclusion. Switching to the (also open-source) Qt toolkit is the chosen solution for most for cross-platform graphical software, and so this is what we have now done as well. The experience is much improved as a result. Being the standard cross-platform \textsc{gui} toolkit, Qt is already available in the standard Anaconda Python distribution~\cite{continuum_analytics_anaconda_2018}, which is the preferred Python distribution among scientists at the present time. With our \texttt{qtutils} package, an icon set is available, obviating the need to install a separate icon pack as was previously the case. Most importantly, the Qt software project exists to serve the needs of graphical programs generally, and is used by many major cross-platform projects. We therefore have confidence that its incentives are aligned with those of the labscript suite, and that we can confidently rely on it in a way we could not with the \textsc{gtk} project.


\subsection{Python 3}

The labscript suite was initially written in version 2.7 of the Python programming language, even though version 3 of Python had been released several years prior. The Python community has in this time been in a decade-long transition from one version to the next due to some non-trivial differences between the two versions of the language. I believe we made the right decision to initially use Python version 2.7, as many of the technologies the labscript suite relies on did not have Python 3 compatibility for some time. However, the point of inflection in the adoption curve for Python 3 has occurred in the last two years or so, and now is the right time for Python 3 adoption. With the help of 3rd party contributors (primarily Jan Werkmann), the entirety of the labscript suite has now been ported to run on both Python 2 and Python 3, though we do not consider the support `official' until more testing has been performed, particularly using hardware not in use by the groups that are running with Python 3 daily.

We do not expect such an extended issue such as this to occur again: the Python core developers consider this transition to be a one-off and future porting efforts will likely be no more effort than the usual required to keep up with minor changes between language versions.

\subsection{More devices, more features, general polish}

There are more devices with compatibility with the labscript suite, and more models and features of existing devices are now supported. The programs are easier to use, and many cases where obscure errors were thrown have been replaced with friendlier error messages explaining the situation in human-readable terms. Following is an incomplete list of minor to modest usability improvements:

\begin{itemize}
    \item \texttt{BLACS} now has a plugin to delete shots that are repeated versions of previous shots. This prevents unnecessary consumption of disk space when these shots are running only to keep an experiment `warm' (initially implemented by Ian Spielman, and re-implemented by me as a plugin for \texttt{BLACS}).
    
    \item \texttt{lyse} now more gracefully handles shot files that have been deleted off disk: declining to run single-shot analysis on them, but keeping their data in the dataframe available for multi-shot analysis until they are deleted from the \texttt{lyse} interface. This aids in, for example, diagnosing a day-long drift in some performance characteristic of the experiment even though most shot files are deleted due to the aforementioned desire to save disk space (implemented by me).
    
    \item \texttt{lyse} is now more performant, only updating those values of the dataframe that have changed, and minimising the number of times it opens a HDF5 file. This change was added by a 3rd party contributor to improve performance for very large numbers of very short duration shots, as is common in ion trapping (implemented by Jan Werkmann with changes by me).
    
    \item \texttt{BLACS} has had some bugs resolved that unnecessarily introduced delays on the order of $0.5\unit{s}$ in between running shots. These delays were not very noticeable for the cold atom experiments of order $15\textrm{--}30\unit{s}$, but again are important for the ion trappers (implemented by me and Philip Starkey).
    
    \item \texttt{BLACS} tabs now have a separate optional terminal output for each device subprocess, allowing simpler debugging and development of devices (implemented by me).
    
    \item More flexible camera interface. There are now a number of camera `servers' in use by various groups playing the role that \texttt{BIAS} plays at Monash, including a fork of \texttt{BIAS} named \texttt{unBIASed} by Ian Spielman (changes made to facilitate communication with Python camera servers implemented by me)
    
    \item \texttt{labscript} can now accept arbitrary function ramps using user-supplied functions, not limited to the built-in list of functional forms. This has always been possible somewhat manually, but now has a more friendly interface (implemented by me).
    
    \item There is now a unified interface for saving and retrieving configuration settings of devices in labscript to the \textsc{hdf5}, including Javascript Object Notation serialisation for complex data types that do not coincide with a \textsc{hdf5} datatype. This replaces a number of ad-hoc serialisation methods previously in use to store configuration settings of devices (specification designed by Ian Spielman and core developers, implementation by Ian Spielman and me).
    
    \item There is now a unified \texttt{labscript} device driver for National Instruments DAQmx devices, removing the code duplication and complexity of maintaining multiple device classes for this range of devices. This class exists in the fork of the \texttt{labscript\_devices} repository in use by the Spielman group at the Joint Quantum Institute, but will be merged into the mainline codebase soon---it is already in use by groups who are not otherwise using the Spielman fork of the code, and so has undergone some testing and bugfixes outside of the hardware in the Spielman group. In time the model specific code will likely be removed in favour of the unified interface (implemented by Ian Spielman).
    
    \item The ability to mark certain points in time of the experiment with a named marker, visible in \texttt{runviewer} to visibly delineate different stages of the experiment (implemented by Jan Werkmann).
    
    \item A `nonlinear time' mode for runviewer, where the time axis is not linear but instead uses a different timestep for the different stages of the experiment as described by the markers. This allows short timescales and longer timescales to be visible on the same plots in \texttt{runviewer}. (implemented by Jan Werkmann with changes by Shaun Johnstone).
    
    \item The ability to mark digital outputs as `inverted', such that digital low represents a device being on, semantically speaking. The buttons for these outputs are represented with different colours in the \texttt{BLACS} interface to avoid confusion (implemented by Jan Werkmann).
    
    \item Gated clocks: devices with vastly different memory capabilities can receive clocking signals from the same clocking device such as a PulseBlaster, but on different outputs such that the clock ticks intended for one device are not received by other devices. There is still a single pseudoclock, but its outputs are `gated'---whilst the clock is ticking for one device it is not ticking for another. Two devices configured in this way are still however sharing a clock in a sense: they cannot both receive rapid clock ticks simultaneously but at different rates, multiple pseudoclock devices are still required for this (implemented by Philip Starkey).
    
    \item \texttt{lyse} plots can be copied to the clipboard with a button click, reducing the number of steps to include plots in a digital lag log book (implemented by me).
    
    \item \texttt{runmanager}, \texttt{lyse}, and \texttt{runviewer} now have the ability to save and load configuration settings, such that the same sets of globals files in the case of \texttt{runmanager} or the same sets of analysis routines in the case of \texttt{lyse} and the same view settings in the case of \texttt{runviewer} can be loaded at startup of each application (implemented by me for \texttt{runmanager} and Jan Werkmann for \texttt{lyse} and \texttt{runviewer}).
    
    \item \texttt{runmanager} now allows finer control over parameter spaces, including randomising the order of a parameter space scan on a per-axis basis, and control over the nesting order in which the axes are looped over (implemented by Philip Starkey).
\end{itemize}

\subsection{Optimisation}

The program \texttt{mise}, mentioned in the paper, has been deprecated. Nothing has replaced it, though due to the modularity of the labscript suite, optimisation is still possible through use of the \texttt{runmanager} library directly. This is a testament for the pluggability of the labscript suite components, but could nonetheless be improved.

I plan to improve this functionality in the future, and one of the near-term development goals is to add a `remote' application programming interface (\textsc{api}) for \texttt{runmanager}. This will enable a program to control a running instance of \texttt{runmanager} to set the values of globals and initiate shot compilation and submission to \texttt{BLACS}. This will be a much simpler interface as well as being compatible with just-in-time compilation, discussed below.

\subsection{Just-in-time compilation}\label{sec:jit}

One feedback mechanism not previously anticipated---more accurately described as \emph{feed-forward} in this context---is the need to modify one or more parameters for the very next shot to be run on the experiment, but otherwise remain performing some parameter space scan or repetition. For example, in the Spielman group's atom chip lab, an environmental magnetic field drift on a several hour timescale is corrected for by performing an error measurement each shot, to be fed-forward to the next shot as a change in the applied field bias. Other than this, the experiment is not performing any optimisation or feedback. In the chip lab, this functionality is implemented by having \texttt{BLACS} use the \texttt{runmanager} \textsc{api} to re-compile the shot files just before running them, to be sure to include the updated magnetic field bias estimate. 

This works, and is an example of functionality being able to be modified by end users to serve an immediate need. However I would like to move this `just-in-time' compilation into \texttt{runmanager}, so that the shot is compiled only once rather than being recompiled. Compilation by \texttt{BLACS} is unappealing since it may be on a different computer with different versions of the code being compiled, leading to subtle errors, and that the output is not visible in its interface, making debugging difficult (though this could of course be changed if we embraced compilation ocurring in \texttt{BLACS}). I have wasted some time in the chip lab modifying device driver code, restarting \texttt{runmanager}'s compilation subprocess  and expecting the changes to be reflected in the experiment's outcome, only for the experiment to be unchanged because the recompilation in \texttt{BLACS} still had an older version of the code loaded.

For this reason as well the applicability to optimisation mentioned above, I plan to implement both a remote \textsc{api} for \texttt{runmanager} as well as a `compilation queue' containing shots yet to be compiled, whose variables can still be changed (possibly remotely) up until the moment \texttt{BLACS} requests a new shot.

\subsection{Fixed duration shots}

Since \texttt{BLACS} takes a usually small---but variable---amount of time to program the hardware in between shots, this contributes to a variation in the average proportion of time an atom dispenser is receiving current or ultraviolet light-induced desorption is active, leading to vapour pressure variations in experiments that operate in this manner. In the Spielman fork of the \texttt{BLACS} repository, there is functionality to set a fixed overall duration for an experiment, such that after programming devices, \texttt{BLACS} waits some additional amount of time such that experiments are run at precisely equal intervals. This can be used not only to smooth out the variations in programming time, but also to smooth our variations in actual shot duration caused by changes of parameters that affect the shot duration, or changes in shot duration due to variable-length waits while the experiment is paused, such as servoing a MOT load as mentioned in Section~\ref{sec:its_code}. This feature is yet to be merged into the mainline labscript suite codebase from the Spielman fork.

\subsection{Remote devices}

A work-in-progress is to allow devices to be connected to any computer, not just the one that \texttt{BLACS} is running on. As mentioned in Section~\ref{sec:unix_philosophy}, this allows one to avoid long signal cables and their associated propagation delays and potential ground loops, as well as to make better use of limited computer resources by spreading processing over more computers. It also would allow one to make better use of computer screen real estate if the graphical interfaces for each device within \texttt{BLACS} could be presented on a different computer as well, since the \texttt{BLACS} interface can become quite cluttered with a large number of devices. One reason for making a separate camera control program in the form of \texttt{BIAS} was to be able to view images immediately at all times without having to ensure the correct tab in the \texttt{BLACS} interface is selected. Being able to display these tabs as separate windows on different screens or computers will obviate this need and allow cameras to be once again treated the same as other devices.\footnote{This is not the only reason \texttt{BIAS} was made as a separate system, another reason was the availability of software libraries for interacting with certain cameras, these were available for LabVIEW at the time, but not Python. Python wrappers, \texttt{pyvisa}~\cite{torsten_bronger_pyvisa_2018} and \texttt{pynivision}~\cite{peter_johnson_frc_team_294_pynivision_2015} for the National Instruments \texttt{VISA} and \texttt{NI-Vision} libraries have since become available, removing the need for LabVIEW to be used with cameras or other devices requiring these interfaces.}

In discussion with developers and users, we have designed a specification for how the desired layout of devices on a network will be described by users, and we have a partial implementation. Most of the work toward this has been in the \texttt{zprocess} package, which I have been adapting to these needs, including the use on encryption to ensure that the ability to start processes on remote computers is secure. This feature in \texttt{zprocess} is nearly complete, after which some work on \texttt{BLACS} will need to be done to implement the designed specification and make the appropriate requests to \texttt{zprocess} to launch remote processes for talking to hardware and displaying the graphical interfaces for them. These two features are planned to be separate, such that \texttt{BLACS}, the graphical interface for a specific device, and the device itself can be on the same computer, or two, or three, for maximum flexibility in where the graphical interfaces and actual hardware is located within the lab.

\section{Labscript version 3}

The \texttt{labscript} compiler itself is the oldest part of our codebase, and has changed significantly since its initial incarnation. We have become more skilled programmers in the $7$ years since it was first written, and some design decisions have proved to be the poorer choices. For example, most processing performed by \texttt{labscript} during processing is \emph{destructive}---that is, new data replaces old data as processing steps proceed. Specifically, timing delays are incorporated by replacing timing data in instructions, rather than introducing new variables in code specifically for the delayed timing data whilst leaving the original timing information intact. This makes it difficult to debug where timing problems have occurred, and makes the code fragile to the introduction of bugs in which timing offsets are accidentally taken into account twice or not at all, as opposed to exactly once as required. Furthermore, these timing calculations are performed mostly using floating point arithmetic, and so all comparisons need to be performed with some tolerance or rounding. This is error-prone and unnatural given that the hardware devices generally have quantised timing in their instructions. Finally, by the time an exception occurs in \texttt{labscript} indicative of the user requesting something not possible (such as two instructions closer together in time than the hardware is capable of), \texttt{labscript} no longer has much information about where in the user's code the instruction originated, making it difficult to give the user information that helps them resolve the issue.

To address these three concerns, I have been working on an experimental restructuring of the core instruction and timing processing of \texttt{labscript}, in which all processing is non-destructive, the points in the user's code where instructions are created are noted for later use in error messages, and all timing calculations are performed using integer arithmetic after quantising timing details as early as possible in processing according to the time resolution of the pseudoclock controlling the timing of each device. This project, called \texttt{labscript\_core}, if successful will eventually replace the part of \texttt{labscript} responsible for timing calculations and instruction handling, making the code better from both the perspectives of users and developers. If possible I will keep the timing computations separate from the other higher level parts of \texttt{labscript} (globals, device properties, \textsc{hdf5} files) so that it can be independently tested (ideally in the context of an automated test suite) and verified so that we can have a high degree of confidence in the output it produces, and confidence that regressions have not been introduced when changes are made.


\section{Other future developments}

A pressing concern is to unify the mainline labscript code with the Spielman group's fork of the code. This will involve merging (or re-implementing in the mainline codebase) the remaining features present in the Spielman fork as discussed in the previous sections, as well as others I have not mentioned such as a progress bar showing the progression of the experiment, and the ability to insert small analysis scripts to be executed by BLACS at the end of a shot with the sole purpose of updating parameters in \texttt{runmanager} for feed-forward functionality as described in Section~\ref{sec:jit}.

There are a number of 3rd party contributions (mostly authored by Jan Werkmann) awaiting approval by a core maintainer such as myself or Philip Starkey. Some of these are:
\begin{itemize}
    \item Analog input widgets for \texttt{BLACS}: these show a numerical value for the voltage of each analog input a device has, or optionally can display an interactively updating plot of the voltage trace over time.
    \item Plugin tabs for \texttt{BLACS}: this allows plugins for \texttt{BLACS} to insert tabs into its graphical interface, allowing plugins to have rich interfaces of their own without having to interfere with the main interface of \texttt{BLACS}
\end{itemize}

Other changes proposed but not implemented include:

\begin{itemize}
\item `Analysis globals': like the globals set in \texttt{runmanager}, but set in \texttt{lyse} instead. Presently, users are `abusing' globals set in \texttt{runmanager} in order to configure how analysis will run. For example, there are globals being set by users that tell analysis code which pair of variables to plot against each other. As this may change after a shot has run, an interface where `analysis globals' can be set and used by analysis routines would be preferable.
\end{itemize}

Finally, the entire project would benefit from more and better documentation. Whilst documentation exists, it is not thorough enough and does not keep up to date with changes to the code. Instead, crucial information is often hidden in comments within the code. The Python community has the solution to this problem, which is to use libraries that turn code comments into proper documentation. This then creates incentives to write and update these comments to a higher standard, knowing that they will be visible in official documentation---and this standard is more likely to be enforced during code reviews that occur when pull requests are made for changes to be included in the mainline code repository.

Because the labscript suite is open source, an effective strategy to implementing a change such as this is to sow the seeds what we would like to see by putting the documentation rendering mechanism in place despite the current inadequacy of the documentation contents, and then require that contributions (from core developers or otherwise) in future amend the documentation comments (called `docstrings' in Python parlance) appropriately. This way over time the documentation will improve, and being code rather than a \textsc{pdf} or Microsoft Word document, be amenable to pull requests and bug reports in the same manner as the rest of the code, which we have seen leads to inexorable improvement via an open process that accepts external fixes from others.

There is also a substantial quantity of best-practices and lore built up about hardware as well as software, including many tips and tricks that are specific to certain setups. Whilst the labscript suite has a mailing list in which much of this information is exchanged, it would probably benefit the project to have a user-editable wiki, to decrease the barrier-to-entry for users to share this type of domain-specific knowledge outside the context of an email thread even though it may not suit the official project documentation.


\section{Conclusion}

The labscript suite is an increasingly mature software project for control of hardware-timed experiments. It has an increasing number of users and contributors, and has evolved to keep up with changing software environments in the sense of switching to use more dependable software libraries such as the Qt \textsc{gui} toolkit, and of keeping up with updates in language and library changes, such as the shift to Qt version 5 and to Python 3. It is a living project accepting changes from non-core developers, and is free for anybody to use under a permissive license. Due to the modular design and open development process, the labscript suite has thus far avoided some of the pitfalls that befall many laboratory control systems and software, such as relegation to legacy software or hardware environments due to a lack of development effort and testing to keep them up to date, or long-standing bugs not being resolved because a fix applied in one place has no mechanism of making it into other users' installs of the software, or because the source code is only understood by or available to a small few. The labscript suite is hardware-agnostic, ensuring its use is not restricted to officially sanctioned or in-house hardware. And it is written in a very popular programming language with an abundance of on-line resources and a vibrant community behind it, within both scientific and software engineering circles. Rather than the implementation details of the code itself, it is these decisions that I think are causing the project to thrive and be as beneficial to experiment physics research as it has.

\section{Project attribution}

todo: Who made which code by lines changed?

summarise who wrote each app initially and designed interfaces. Summarise the large changes that each has gone through, i.e. rewrites by phil, then me, then phil, etc. Acknowledge testers!

\section{Reproduced publication: A scripted control system for autonomous hardware-timed experiments}

See over page for a reproduction of our 2013 paper, \emph{A scripted control system for autonomous hardware-timed experiments}. Reproduced with permission [blah blah]





\includepdf[pages=2-]{labscript_paper/labscript_paper.pdf}
